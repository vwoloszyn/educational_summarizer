{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import math\n",
    "\n",
    "try:\n",
    "    import numpy\n",
    "except ImportError:\n",
    "    numpy = None\n",
    "\n",
    "from sumy.summarizers._summarizer import AbstractSummarizer\n",
    "from sumy._compat import  to_unicode, unicode, string_types, Counter\n",
    "\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "from operator import attrgetter\n",
    "from collections import namedtuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "educational_description = pd.read_csv(\"movie.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt_test=\"Description:     Nemo, a young clownfish, strays from the safety of the Great Barrier Reef and is captured by a diver. Placed in a dentist's aquarium in an office with an ocean view, he finds a group of fish with an escape plan. Meanwhile, Nemo's father searches for his son, meeting a number of ocean creatures along the way. Luck and Disney screenwriting lead to a happy reunion. \\\\\n",
    "Benefits: 'Finding Nemo' can be used to jump-start the natural interest that children have in ocean life, coral reefs, and marine biology. It also teaches lessons about friendship, obeying parents, and avoiding dangerous situations. \\\\\n",
    "This Learning Guide provides information about the animals featured in the movie. The Guide can also be used as the basis for a longer discussion of concepts from biology and coral reefs. Discussion questions focus on the animals shown in the film, biological concepts, and the film's lessons for social-emotional learning. \\\\\n",
    "Possible Problems:  None. \\\\\n",
    "Parenting Points: This film provides an excellent example of what can happen when kids disobey their parents and place themselves at risk. You may confront the issue directly and ask \\\"How did Nemo get into all that trouble?\\\" However, since children identify with Nemo, it may be better to approach the question obliquely. Comment about how lucky Nemo was to get out of the dentist's fish tank and how lucky he was that his father survived all the dangers of the long swim when he was searching for Nemo. The kids know very well that Nemo disobeyed his father and, as a result, was captured. \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,1,1,1]\n",
    "b=[2,2,2,2]\n",
    "numpy.array(a)*2+numpy.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05222222  0.05555556  0.05222222  0.06666667  0.07222222  0.06666667\n",
      "  0.05555556  0.08333333  0.07222222  0.06666667  0.06888889  0.05\n",
      "  0.05555556  0.08555556  0.09666667]\n",
      "The Guide can also be used as the basis for a longer discussion of concepts from biology and coral reefs.\n",
      "Comment about how lucky Nemo was to get out of the dentist's fish tank and how lucky he was that his father survived all the dangers of the long swim when he was searching for Nemo.\n",
      "The kids know very well that Nemo disobeyed his father and, as a result, was captured.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "\n",
    "\n",
    "class biased_LexRank():\n",
    "   \n",
    "\n",
    "    threshold = 0.1\n",
    "    epsilon = 0.1\n",
    "    _stop_words = frozenset()\n",
    "    words=[]\n",
    "    sentences=[]\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def stop_words(self):\n",
    "        return self._stop_words\n",
    "\n",
    "    @stop_words.setter\n",
    "    def stop_words(self, words):\n",
    "        self._stop_words = frozenset(map(self.normalize_word, words))\n",
    "\n",
    "    def __call__(self, text, text_bias, bias, sentences_count):\n",
    "        self._ensure_dependencies_installed()\n",
    "\n",
    "        \n",
    "        \n",
    "        sentences = nltk.sent_tokenize(text) # this gives us a list of sentences\n",
    "        sentences_words = [self._to_words_set(s) for s in sentences]\n",
    "        if not sentences_words:\n",
    "            return tuple()\n",
    "        tf_metrics = self._compute_tf(sentences_words)\n",
    "        idf_metrics = self._compute_idf(sentences_words)\n",
    "        matrix = self._create_matrix(sentences_words, self.threshold, tf_metrics, idf_metrics)\n",
    "        scores = self.power_method(matrix, self.epsilon)\n",
    "        \n",
    "        \n",
    "        bias_lex_scores=scores[:]\n",
    "        for ind,sent in enumerate(sentences):\n",
    "            bias_sentences = nltk.sent_tokenize(text_bias) # this gives us a list of sentences\n",
    "            bias_sentences.append(sent)\n",
    "            bias_sentences_words = [self._to_words_set(s) for s in bias_sentences]\n",
    "            bias_tf_metrics = self._compute_tf(bias_sentences_words)\n",
    "            bias_idf_metrics = self._compute_idf(bias_sentences_words)\n",
    "            bias_matrix = self._create_matrix(bias_sentences_words, self.threshold, bias_tf_metrics, bias_idf_metrics)\n",
    "            bias_scores = self.power_method(bias_matrix, self.epsilon)\n",
    "            sent_score = bias_scores[-1]\n",
    "            \n",
    "            bias_lex_scores[ind]=(numpy.array(bias_lex_scores[ind])*(1-bias))+(numpy.array(sent_score)*(bias))\n",
    "        #print (scores)\n",
    "        #print (bias_scores)\n",
    "        print (bias_lex_scores)\n",
    "        \n",
    "        ratings = dict(zip(sentences, scores))\n",
    "        return self._get_best_sentences(sentences, sentences_count, ratings)\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_dependencies_installed():\n",
    "        if numpy is None:\n",
    "            raise ValueError(\"LexRank summarizer requires NumPy. Please, install it by command 'pip install numpy'.\")\n",
    "\n",
    "    def _to_words_set(self, sentence):\n",
    "        \n",
    "        ps = PorterStemmer()\n",
    "\n",
    "        words = map(self.normalize_word, nltk.word_tokenize(sentence))\n",
    "        return [ps.stem(w) for w in words if w not in self._stop_words]\n",
    "\n",
    "    def _compute_tf(self, sentences):\n",
    "        tf_values = map(Counter, sentences)\n",
    "\n",
    "        tf_metrics = []\n",
    "        for sentence in tf_values:\n",
    "            metrics = {}\n",
    "            max_tf = self._find_tf_max(sentence)\n",
    "\n",
    "            for term, tf in sentence.items():\n",
    "                metrics[term] = tf / max_tf\n",
    "\n",
    "            tf_metrics.append(metrics)\n",
    "\n",
    "        return tf_metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def _find_tf_max(terms):\n",
    "        return max(terms.values()) if terms else 1\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_idf(sentences):\n",
    "        idf_metrics = {}\n",
    "        sentences_count = len(sentences)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            for term in sentence:\n",
    "                if term not in idf_metrics:\n",
    "                    n_j = sum(1 for s in sentences if term in s)\n",
    "                    idf_metrics[term] = math.log(sentences_count / (1 + n_j))\n",
    "\n",
    "        return idf_metrics\n",
    "\n",
    "    def _create_matrix(self, sentences, threshold, tf_metrics, idf_metrics):\n",
    "        \"\"\"\n",
    "        Creates matrix of shape |sentences|×|sentences|.\n",
    "        \"\"\"\n",
    "        # create matrix |sentences|×|sentences| filled with zeroes\n",
    "        sentences_count = len(sentences)\n",
    "        matrix = numpy.zeros((sentences_count, sentences_count))\n",
    "        degrees = numpy.zeros((sentences_count, ))\n",
    "\n",
    "        for row, (sentence1, tf1) in enumerate(zip(sentences, tf_metrics)):\n",
    "            for col, (sentence2, tf2) in enumerate(zip(sentences, tf_metrics)):\n",
    "                matrix[row, col] = self.compute_distance(sentence1, sentence2, tf1, tf2, idf_metrics)\n",
    "\n",
    "                if matrix[row, col] > threshold:\n",
    "                    matrix[row, col] = 1.0\n",
    "                    degrees[row] += 1\n",
    "                else:\n",
    "                    matrix[row, col] = 0\n",
    "\n",
    "        for row in range(sentences_count):\n",
    "            for col in range(sentences_count):\n",
    "                if degrees[row] == 0:\n",
    "                    degrees[row] = 1\n",
    "\n",
    "                matrix[row][col] = matrix[row][col] / degrees[row]\n",
    "\n",
    "        return matrix\n",
    "    def normalize_word(self, word):\n",
    "        return str(word).lower()\n",
    "    \n",
    "    def _get_best_sentences(self, sentences, count, rating, *args, **kwargs):\n",
    "        rate = rating\n",
    "        SentenceInfo = namedtuple(\"SentenceInfo\", (\"sentence\", \"order\", \"rating\",))\n",
    "        if isinstance(rating, dict):\n",
    "            assert not args and not kwargs\n",
    "            rate = lambda s: rating[s]\n",
    "\n",
    "        infos = (SentenceInfo(s, o, rate(s, *args, **kwargs))\n",
    "            for o, s in enumerate(sentences))\n",
    "\n",
    "        # sort sentences by rating in descending order\n",
    "        infos = sorted(infos, key=attrgetter(\"rating\"), reverse=True)\n",
    "        # get `count` first best rated sentences\n",
    "        if not isinstance(count, ItemsCount):\n",
    "            count = ItemsCount(count)\n",
    "        infos = count(infos)\n",
    "        # sort sentences by their order in document\n",
    "        infos = sorted(infos, key=attrgetter(\"order\"))\n",
    "\n",
    "        return tuple(i.sentence for i in infos)\n",
    "\n",
    "    #@staticmethod\n",
    "\n",
    "    @staticmethod\n",
    "    def power_method(matrix, epsilon):\n",
    "        transposed_matrix = matrix.T\n",
    "        sentences_count = len(matrix)\n",
    "        p_vector = numpy.array([1.0 / sentences_count] * sentences_count)\n",
    "        lambda_val = 1.0\n",
    "\n",
    "        while lambda_val > epsilon:\n",
    "            next_p = numpy.dot(transposed_matrix, p_vector)\n",
    "            lambda_val = numpy.linalg.norm(numpy.subtract(next_p, p_vector))\n",
    "            p_vector = next_p\n",
    "\n",
    "        return p_vector\n",
    "    @staticmethod\n",
    "    def compute_distance(sentence1, sentence2, tf1, tf2, idf_metrics):\n",
    "        common_words = frozenset(sentence1) & frozenset(sentence2)\n",
    "\n",
    "        numerator = 0.0\n",
    "        for term in common_words:\n",
    "            numerator += tf1[term]*tf2[term] * idf_metrics[term]**2\n",
    "\n",
    "        denominator1 = sum((tf1[t]*idf_metrics[t])**2 for t in sentence1)\n",
    "        denominator2 = sum((tf2[t]*idf_metrics[t])**2 for t in sentence2)\n",
    "\n",
    "        if denominator1 > 0 and denominator2 > 0:\n",
    "            return numerator / (math.sqrt(denominator1) * math.sqrt(denominator2))\n",
    "        else:\n",
    "            return 0.0\n",
    "        \n",
    "class ItemsCount(object):\n",
    "    def __init__(self, value):\n",
    "        self._value = value\n",
    "\n",
    "    def __call__(self, sequence):\n",
    "        if isinstance(self._value, string_types):\n",
    "            if self._value.endswith(\"%\"):\n",
    "                total_count = len(sequence)\n",
    "                percentage = int(self._value[:-1])\n",
    "                # at least one sentence should be chosen\n",
    "                count = max(1, total_count*percentage // 100)\n",
    "                return sequence[:count]\n",
    "            else:\n",
    "                return sequence[:int(self._value)]\n",
    "        elif isinstance(self._value, (int, float)):\n",
    "            return sequence[:int(self._value)]\n",
    "        else:\n",
    "            ValueError(\"Unsuported value of items count '%s'.\" % self._value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return to_string(\"<ItemsCount: %r>\" % self._value)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02611111  0.02777778  0.02611111  0.03333333  0.28611111  0.03333333\n",
      "  0.02777778  0.04166667  0.03611111  0.03333333  0.03444444  0.025\n",
      "  0.02777778  0.04277778  0.04833333]\n",
      "\\Benefits: 'Finding Nemo' can be used to jump-start the natural interest that children have in ocean life, coral reefs, and marine biology.\n",
      "Comment about how lucky Nemo was to get out of the dentist's fish tank and how lucky he was that his father survived all the dangers of the long swim when he was searching for Nemo.\n",
      "The kids know very well that Nemo disobeyed his father and, as a result, was captured.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "txt_bias=\"natural interest\"\n",
    "summarizer = biased_LexRank()\n",
    "for sentence in summarizer(txt_test, txt_bias, 0.5, 3):\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
